长程任务
- 目标：
	- 支持可定制的长程任务 agent，多次调用工具完成任务；
	- 让模型突破简短问答的套路，实现复杂的推理和工具调用路径，并在过程中保持在上下文窗口的最优区间
- 路径一：强化学习 --> 优化模型能力，以具体任务为导向，训练模型自主完成复杂任务的能力
- 路径二：优化 Agent 工程框架

### RL 端到端
Agentic RL：通过 RL 范式，端到端优化 Agent 的规划、推理、使用工具、管理记忆和自我反思能力；提升模型在目标领域的效果，同时不破坏它的通用能力。

例子：Deep search
- 构建全自动化数据合成管线
	- 参考 WebShaper（通义）和 TaskCraft（OPPO）
	- 构建多跳问答数据集流程
		- 从 Wiki 构建种子问题 --> 自然语言问题 --> 形式化问题转换为图（问题形式化） --> 扩展节点为子图 --> 合并子图 --> 生成新的自然语言问题 --> 问题验证
			- 问题扩展：内嵌：将某个常量节点扩展为子图；外扩：把答案本身扩展为子图
			- 问题验证：构建 verifier agent ，使用更强的模型多次独立回答问题，保证构建出来的问题可解
- RL 框架（面向长航时）
	- 基于 Verl 框架
	- Agent 运行时和训练框架解耦
		- 引入 LangChain ChatModel 兼容层（包装LLM、训练框架多轮轨迹捕捉），构建的 Deep search agent 依赖 LangChain 兼容层， LangChain 兼容层自动捕捉 agent 和模型的交互，使 RL 框架能自动跟踪 LLM 调用并用于训练
	- 多轮 RL 优化：Reward 流水线并行计算、动态组批次
	- Token-in-token-out
- 算法策略组合
- 长上下文工程设计 & 工程优化
	- 网页工具：page_vist 工具访问网页全文，超出模型上下文窗口 -- 大模型根据网页全文，返回针对 `information_needed`的总结
	- 参考 RAG 思路，先分块，再递归地做 summary
	- 缓存设计
		- 工具调用、网页抓取、LLM-As-judge 阶段耗时高
		- Agentic RL 特点：Agent 处理相同 prompt 时，多样性较低，重复搜索和访问
		- 使用中心化缓存：减少重复调用
 
### RL + 工程框架
规划+执行模式，多 agent 协同，一般 Planner 由大尺寸模型驱动，Researcher 为 RL 模型


传统 Agent Loop 的局限
- 模型总是倾向快速回答（25年9月前，开源模型），之前模型没有针对长程 agentic 做训练，SFT 多问答数据，偏好快速回答，即使让模型输出多步计划，总是执行两步后倾向直接回答用户问题
- 上下文限制

解决思路
- 规划
	- Anthropic 三个实践案例
		- Think 工具：将思考结构化为 thought / plan / action
		- Sequential Thinking MCP：分布推理、动态调整、中间步骤可调用
		- Claude Code 待办清单
- 模型能力的差异，导致 claude 上有效果的方法，在开源模型上不一定有效（模型规划了多步，但只执行了其中几步）
	- Planner-Executor 架构，强制逐步执行
	- Agent loop 前加入 Planner，每步执行后强制 review，更新规划将下一步子任务下发
	- Executor（子agent）只执行当前步骤所需工具调用
		- Executor 工具调用的上下文是否返回主 agent，还是只返回结果？-- 不给上下文，Planner 和 Executor 隔离上下文，解决窗口不足的问题
- 子 agent 之间的两类上下文
	- 原本设想是子 agent 之间的上下文都独立，但可能规划出来的任务，两个子 agent 之间需要进行上下文共享/信息交换
		- 子 agent 之间的两类上下文
			- 对话上下文：临时、孤立
			- 环境上下文 -- 永久、共享，共享文件系统的环境上下文
		- 思路：用虚拟「文件系统」作为共享工作空间
			- context_create_file
			- context_read_file
			- context_list_files
		- 采用沙箱做文件系统  / 采用变量模拟许年文件系统
			- A2A 协议还需要吗？-- 目前主从 agent 关系的框架下，可以不需要，可以用文件系统；remote、跨应用时需要